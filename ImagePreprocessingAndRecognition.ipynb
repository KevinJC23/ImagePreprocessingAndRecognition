{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **IMPORT LIBRARY**"
      ],
      "metadata": {
        "id": "wfzKEZ6DrUZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Emf7H-QKd9Ji",
        "outputId": "05e72d80-486c-45b8-8cf8-ae41f5c6eb50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.24.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio)\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.1)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.24.0-py3-none-any.whl (46.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.24.0 gradio-client-1.8.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.5 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.1 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwrSXeWSpYbN"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.fftpack import dct, idct\n",
        "from skimage.morphology import skeletonize"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. BASIC IMAGE OPERATIONS**"
      ],
      "metadata": {
        "id": "Q-2SEreWrVHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grayscale\n",
        "def to_greyscale(image):\n",
        "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Negative\n",
        "def to_negative(image):\n",
        "    return 255 - image\n",
        "\n",
        "# Adjust Color\n",
        "def adjust_color(image, r_factor=1.0, g_factor=1.0, b_factor=1.0):\n",
        "    b, g, r = cv2.split(image)\n",
        "    b = np.clip(b * b_factor, 0, 255).astype(np.uint8)\n",
        "    g = np.clip(g * g_factor, 0, 255).astype(np.uint8)\n",
        "    r = np.clip(r * r_factor, 0, 255).astype(np.uint8)\n",
        "    return cv2.merge([b, g, r])\n",
        "\n",
        "# Flip\n",
        "def flip_image(image, direction=\"horizontal\"):\n",
        "    flip_code = {'horizontal': 1, 'vertical': 0, 'diagonal': -1}\n",
        "    return cv2.flip(image, flip_code.get(direction, 1))\n",
        "\n",
        "# Translate\n",
        "def translate(image, x_offset, y_offset):\n",
        "    rows, cols = image.shape[:2]\n",
        "    M = np.float32([[1, 0, x_offset],\n",
        "                    [0, 1, y_offset]])\n",
        "    return cv2.warpAffine(image, M, (cols, rows))\n",
        "\n",
        "# Scale\n",
        "def scale_image(image, width=None, height=None, keep_aspect_ratio=True):\n",
        "    h, w = image.shape[:2]\n",
        "    if keep_aspect_ratio:\n",
        "        if width is not None:\n",
        "            ratio = width / float(w)\n",
        "            height = int(h * ratio)\n",
        "        elif height is not None:\n",
        "            ratio = height / float(h)\n",
        "            width = int(w * ratio)\n",
        "    if width is None:\n",
        "        width = w\n",
        "    if height is None:\n",
        "        height = h\n",
        "    return cv2.resize(image, (width, height), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "# Rotate\n",
        "def rotate(image, angle, clockwise=True):\n",
        "    rows, cols = image.shape[:2]\n",
        "    center = (cols / 2, rows / 2)\n",
        "    if clockwise:\n",
        "        angle = -angle\n",
        "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "    rotated = cv2.warpAffine(image, M, (cols, rows))\n",
        "    return rotated\n",
        "\n",
        "# Crop\n",
        "def crop(image, x, y, w, h):\n",
        "    return image[y:y+h, x:x+w]\n",
        "\n",
        "# Blend\n",
        "def blend(image1, image2, alpha=0.5):\n",
        "    if image2 is None:\n",
        "        return image1  # If No Second Image, Just Return First\n",
        "    if image1.shape != image2.shape:\n",
        "        image2 = cv2.resize(image2, (image1.shape[1], image1.shape[0]))\n",
        "    return cv2.addWeighted(image1, alpha, image2, 1 - alpha, 0)\n",
        "\n",
        "# Brightness & Contrast\n",
        "def adjust_brightness_contrast(image, brightness=50, contrast=1.2):\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    h, s, v = cv2.split(hsv)\n",
        "    v = np.clip(v + brightness, 0, 255).astype(np.uint8)\n",
        "    final_hsv = cv2.merge((h, s, v))\n",
        "    image_brightness = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "    image_float = image_brightness.astype(np.float32)\n",
        "    image_contrast = np.clip(contrast * (image_float - 128) + 128, 0, 255)\n",
        "    return image_contrast.astype(np.uint8)\n",
        "\n",
        "# Color Filter\n",
        "def color_filter(image, lower_bound, upper_bound):\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    mask = cv2.inRange(hsv, lower_bound, upper_bound)\n",
        "    return cv2.bitwise_and(image, image, mask=mask)\n",
        "\n",
        "def apply_sepia(image):\n",
        "    image_float = image.astype(np.float32)\n",
        "    sepia_kernel = np.array([\n",
        "        [0.272, 0.534, 0.131],\n",
        "        [0.349, 0.686, 0.168],\n",
        "        [0.393, 0.769, 0.189]\n",
        "    ])\n",
        "    sepia_image = image_float @ sepia_kernel.T\n",
        "    sepia_image = np.clip(sepia_image, 0, 255)\n",
        "    return sepia_image.astype(np.uint8)\n",
        "\n",
        "def apply_cyanotype(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    cyan_image = np.zeros_like(image)\n",
        "    cyan_image[:, :, 0] = np.clip(gray / 2, 0, 255)  # Blue Channel\n",
        "    cyan_image[:, :, 1] = np.clip(gray, 0, 255)      # Green Channel\n",
        "    cyan_image[:, :, 2] = 255                        # Red Channel\n",
        "    return cyan_image\n",
        "\n",
        "# Border\n",
        "def add_border(image, top, bottom, left, right, color_str=\"(0,0,0)\"):\n",
        "    color = tuple(map(int, color_str.strip(\"()\").split(\",\")))\n",
        "    return cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
        "\n",
        "# Overlay\n",
        "def overlay(image1, image2, x, y, alpha=0.5):\n",
        "    if image2 is None:\n",
        "        return image1\n",
        "    h1, w1 = image1.shape[:2]\n",
        "    h2, w2 = image2.shape[:2]\n",
        "    if y + h2 > h1 or x + w2 > w1:\n",
        "        # Resize Overlay If It Goes Beyond Boundary\n",
        "        new_h = min(h2, h1 - y)\n",
        "        new_w = min(w2, w1 - x)\n",
        "        image2 = cv2.resize(image2, (new_w, new_h))\n",
        "        h2, w2 = new_h, new_w\n",
        "    roi = image1[y:y+h2, x:x+w2]\n",
        "    blended = cv2.addWeighted(roi, 1 - alpha, image2, alpha, 0)\n",
        "    image1[y:y+h2, x:x+w2] = blended\n",
        "    return image1"
      ],
      "metadata": {
        "id": "FSAo8v-9poTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. MATHEMATICAL OPERATIONS ON IMAGES**"
      ],
      "metadata": {
        "id": "PVDDFD4MrvHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pixelwise_operation(image1, image2, operation, brightness_factor=1.2):\n",
        "    if operation == 'Bitwise (NOT)':\n",
        "        # Only Needs Image1\n",
        "        return cv2.bitwise_not(image1)\n",
        "    # For Other Option, We Need 2 Images\n",
        "    if image2 is None:\n",
        "        return image1\n",
        "\n",
        "    # Resize If Mismatch\n",
        "    if image1.shape != image2.shape:\n",
        "        image2 = cv2.resize(image2, (image1.shape[1], image1.shape[0]))\n",
        "\n",
        "    if operation == 'Add':\n",
        "        return cv2.add(image1, image2)\n",
        "    elif operation == 'Subtract':\n",
        "        return cv2.subtract(image1, image2)\n",
        "    elif operation == 'Multiply':\n",
        "        return cv2.multiply(image1, image2)\n",
        "    elif operation == 'Divide':\n",
        "        epsilon = 1e-5\n",
        "        image2 = image2.astype(np.float32) + epsilon\n",
        "        image1 = image1.astype(np.float32)\n",
        "        divided = cv2.divide(image1, image2)\n",
        "        divided_normalized = cv2.normalize(divided, None, 0, 255, cv2.NORM_MINMAX)\n",
        "        return cv2.convertScaleAbs(divided_normalized, alpha=brightness_factor, beta=0)\n",
        "    elif operation == 'Bitwise (AND)':\n",
        "        return cv2.bitwise_and(image1, image2)\n",
        "    elif operation == 'Bitwise (OR)':\n",
        "        return cv2.bitwise_or(image1, image2)\n",
        "    elif operation == 'Bitwise (XOR)':\n",
        "        return cv2.bitwise_xor(image1, image2)\n",
        "    else:\n",
        "        return image1"
      ],
      "metadata": {
        "id": "NFwGIg-gqWCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. TRANSFORMS & FILTERING**"
      ],
      "metadata": {
        "id": "oxQP-8aqr4aW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FFT\n",
        "def fft_image(image: np.ndarray):\n",
        "    if len(image.shape) == 3:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    f = np.fft.fft2(image)\n",
        "    fshift = np.fft.fftshift(f)\n",
        "    magnitude = 20 * np.log(np.abs(fshift) + 1e-8)\n",
        "    return cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "\n",
        "# Mean Blur\n",
        "def mean_blur(image: np.ndarray, ksize: int = 3):\n",
        "    return cv2.blur(image, (ksize, ksize))\n",
        "\n",
        "# Gaussian Blur\n",
        "def gaussian_blur(image: np.ndarray, ksize: int = 3, sigma: float = 1.0):\n",
        "    if ksize % 2 == 0:\n",
        "        ksize += 1\n",
        "    return cv2.GaussianBlur(image, (ksize, ksize), sigma)\n",
        "\n",
        "# Median Blur\n",
        "def median_blur(image: np.ndarray, ksize: int = 3):\n",
        "    if ksize % 2 == 0:\n",
        "        ksize += 1\n",
        "    return cv2.medianBlur(image, ksize)\n",
        "\n",
        "# Sobel Edge\n",
        "def sobel_edge(image: np.ndarray, ksize: int = 3):\n",
        "    if ksize % 2 == 0:\n",
        "        ksize += 1\n",
        "    if len(image.shape) == 3:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=ksize)\n",
        "    sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=ksize)\n",
        "    magnitude = cv2.magnitude(sobelx, sobely)\n",
        "    return np.clip(magnitude, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Canny Edge\n",
        "def canny_edge(image: np.ndarray, t1: float, t2: float):\n",
        "    if len(image.shape) == 3:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    return cv2.Canny(image, t1, t2)\n",
        "\n",
        "# Laplacian Edge\n",
        "def laplacian_edge(image: np.ndarray, ksize: int = 3):\n",
        "    if ksize % 2 == 0:\n",
        "        ksize += 1\n",
        "    if len(image.shape) == 3:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    lap = cv2.Laplacian(image, cv2.CV_64F, ksize=ksize)\n",
        "    return np.clip(np.abs(lap), 0, 255).astype(np.uint8)"
      ],
      "metadata": {
        "id": "pv5QQGGXqZyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. IMAGE ENHANCEMENT**"
      ],
      "metadata": {
        "id": "mxIOvl0vsBIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram Equalization\n",
        "def histogram_equalization(image: np.ndarray):\n",
        "    if len(image.shape) == 2:\n",
        "        return cv2.equalizeHist(image)\n",
        "    else:\n",
        "        b, g, r = cv2.split(image)\n",
        "        b_eq = cv2.equalizeHist(b)\n",
        "        g_eq = cv2.equalizeHist(g)\n",
        "        r_eq = cv2.equalizeHist(r)\n",
        "        return cv2.merge([b_eq, g_eq, r_eq])\n",
        "\n",
        "# Contrast Stretching\n",
        "def contrast_stretch(image: np.ndarray, in_low: int, in_high: int):\n",
        "    img_float = image.astype(np.float32)\n",
        "    img_stretched = (img_float - in_low) * (255.0 / max(in_high - in_low, 1e-6))\n",
        "    return np.clip(img_stretched, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Gamma Correction\n",
        "def gamma_correction(image: np.ndarray, gamma: float = 1.0):\n",
        "    inv_gamma = 1.0 / gamma\n",
        "    table = np.array([(i / 255.0) ** inv_gamma * 255 for i in range(256)]).astype(\"uint8\")\n",
        "    return cv2.LUT(image, table)"
      ],
      "metadata": {
        "id": "6rTBe7v4qtLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. IMAGE COMPRESSION**"
      ],
      "metadata": {
        "id": "dO_KEy2AsI1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RLE\n",
        "def rle_encode(image: np.ndarray):\n",
        "    if len(image.shape) > 2:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    flat = image.flatten()\n",
        "    encoding = []\n",
        "    prev = flat[0]\n",
        "    count = 1\n",
        "    for pixel in flat[1:]:\n",
        "        if pixel == prev:\n",
        "            count += 1\n",
        "        else:\n",
        "            encoding.append((int(prev), count))\n",
        "            prev = pixel\n",
        "            count = 1\n",
        "    encoding.append((int(prev), count))\n",
        "    return encoding\n",
        "\n",
        "def rle_decode(encoding, shape):\n",
        "    flat_image = []\n",
        "    for pixel_value, count in encoding:\n",
        "        flat_image.extend([pixel_value] * count)\n",
        "    return np.array(flat_image, dtype=np.uint8).reshape(shape)\n",
        "\n",
        "# DCT\n",
        "def apply_dct(image, threshold_ratio=0.01):\n",
        "    dct_transformed = dct(dct(image.T, norm='ortho').T, norm='ortho')\n",
        "    dct_thresh = dct_transformed * (np.abs(dct_transformed) > threshold_ratio * np.max(dct_transformed))\n",
        "    img_reconstructed = idct(idct(dct_thresh.T, norm='ortho').T, norm='ortho')\n",
        "\n",
        "    return np.clip(img_reconstructed, 0, 255).astype(np.uint8)"
      ],
      "metadata": {
        "id": "tzPtdIzOqlBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. IMAGE SEGMENTATION**"
      ],
      "metadata": {
        "id": "MDDfUPu2sNvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Global Thresholding\n",
        "def global_threshold(image: np.ndarray, thresh: int = 128):\n",
        "    if len(image.shape) == 3:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(image, thresh, 255, cv2.THRESH_BINARY)\n",
        "    return binary\n",
        "\n",
        "# Adaptive Thresholding\n",
        "def adaptive_threshold(image: np.ndarray, block_size: int = 11, C: int = 2):\n",
        "    if len(image.shape) == 3:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    return cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
        "                                 cv2.THRESH_BINARY, block_size, C)\n",
        "# K-Means\n",
        "def kmeans_segmentation(image: np.ndarray, k: int = 2):\n",
        "    if len(image.shape) == 2:\n",
        "        data = image.reshape((-1, 1))\n",
        "    else:\n",
        "        data = image.reshape((-1, 3))\n",
        "    data = np.float32(data)\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "    _, labels, centers = cv2.kmeans(data, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
        "    centers = np.uint8(centers)\n",
        "    segmented = centers[labels.flatten()]\n",
        "    if len(image.shape) == 2:\n",
        "        segmented = segmented.reshape((image.shape[0], image.shape[1]))\n",
        "    else:\n",
        "        segmented = segmented.reshape((image.shape[0], image.shape[1], 3))\n",
        "    return segmented"
      ],
      "metadata": {
        "id": "YpDCUUy7q3lX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. BINARY PROCESSING**"
      ],
      "metadata": {
        "id": "_0-KB1GuscXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Binarize\n",
        "def binarize_image(image: np.ndarray, thresh: int = 127):\n",
        "    if len(image.shape) == 3:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(image, thresh, 255, cv2.THRESH_BINARY)\n",
        "    return binary\n",
        "\n",
        "# Morphological\n",
        "def morphological_op(binary_image: np.ndarray, op_type: str, ksize: int, iterations: int):\n",
        "    kernel = np.ones((ksize, ksize), np.uint8)\n",
        "    if op_type == 'erosion':\n",
        "        return cv2.erode(binary_image, kernel, iterations=iterations)\n",
        "    elif op_type == 'dilation':\n",
        "        return cv2.dilate(binary_image, kernel, iterations=iterations)\n",
        "    elif op_type == 'opening':\n",
        "        return cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel, iterations=iterations)\n",
        "    elif op_type == 'closing':\n",
        "        return cv2.morphologyEx(binary_image, cv2.MORPH_CLOSE, kernel, iterations=iterations)\n",
        "    else:\n",
        "        return binary_image\n",
        "\n",
        "# Extract Boundary\n",
        "def extract_boundary(binary_image: np.ndarray, ksize: int = 3):\n",
        "    kernel = np.ones((ksize, ksize), np.uint8)\n",
        "    eroded = cv2.erode(binary_image, kernel, iterations=1)\n",
        "    return cv2.subtract(binary_image, eroded)\n",
        "\n",
        "# Skeletonize\n",
        "def skeletonize_image(binary_image: np.ndarray):\n",
        "    from skimage.morphology import skeletonize\n",
        "    if len(binary_image.shape) == 3:\n",
        "        binary_image = cv2.cvtColor(binary_image, cv2.COLOR_BGR2GRAY)\n",
        "    bin_bool = (binary_image > 0)\n",
        "    skeleton = skeletonize(bin_bool)\n",
        "    return (skeleton * 255).astype(np.uint8)"
      ],
      "metadata": {
        "id": "zNjPRgDaq9FD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. IMAGE RESTORATION**"
      ],
      "metadata": {
        "id": "m1aqeGNUsiUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add Noise\n",
        "def add_noise(image: np.ndarray, mean=0, std=25):\n",
        "    gauss = np.random.normal(mean, std, image.shape)\n",
        "    noisy = image.astype(np.float32) + gauss\n",
        "    return np.clip(noisy, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Wiener Filter\n",
        "def wiener_filter(image: np.ndarray, ksize=5, noise_var=0.01):\n",
        "    if len(image.shape) == 3:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    kernel = np.ones((ksize, ksize), np.float32) / (ksize * ksize)\n",
        "    local_mean = cv2.filter2D(image, -1, kernel)\n",
        "    local_var = cv2.filter2D(image ** 2, -1, kernel) - (local_mean ** 2)\n",
        "    noise_var = max(noise_var, 0.0001)\n",
        "    result = local_mean + ((local_var - noise_var) / np.maximum(local_var, noise_var)) * (image - local_mean)\n",
        "    return np.clip(result, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Gaussian Filter\n",
        "def gaussian_filter_restoration(image: np.ndarray, ksize=5, sigma=1.0):\n",
        "    if len(image.shape) == 3:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    return cv2.GaussianBlur(image, (ksize, ksize), sigma)\n",
        "\n",
        "# Inpainting\n",
        "def inpaint_image(image: np.ndarray, top_left, bottom_right, inpaint_radius=3):\n",
        "    mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
        "    r1, c1 = top_left\n",
        "    r2, c2 = bottom_right\n",
        "    mask[r1:r2, c1:c2] = 255\n",
        "    return cv2.inpaint(image, mask, inpaint_radius, cv2.INPAINT_TELEA)"
      ],
      "metadata": {
        "id": "Y8K-skJYrAus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9. IMAGE MATCHING**"
      ],
      "metadata": {
        "id": "MkZrGm6PssOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Detection\n",
        "def detect_and_compute(image: np.ndarray, method='ORB'):\n",
        "    if len(image.shape) == 3:\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray = image\n",
        "    if method == 'ORB':\n",
        "        detector = cv2.ORB_create()\n",
        "    else:\n",
        "        try:\n",
        "            detector = cv2.SIFT_create()\n",
        "        except:\n",
        "            detector = cv2.ORB_create()\n",
        "    kp, des = detector.detectAndCompute(gray, None)\n",
        "    return kp, des\n",
        "\n",
        "# Matching Feature\n",
        "def match_features(img1: np.ndarray, img2: np.ndarray, method='ORB', match_method='BF'):\n",
        "    kp1, des1 = detect_and_compute(img1, method)\n",
        "    kp2, des2 = detect_and_compute(img2, method)\n",
        "    if des1 is None or des2 is None or len(des1) < 2 or len(des2) < 2:\n",
        "        return img1\n",
        "    if match_method == 'BF':\n",
        "        norm_type = cv2.NORM_HAMMING if method=='ORB' else cv2.NORM_L2\n",
        "        bf = cv2.BFMatcher(norm_type, crossCheck=True)\n",
        "        matches = bf.match(des1, des2)\n",
        "    else:\n",
        "        if method == 'ORB':\n",
        "            index_params = dict(algorithm=6, table_number=6, key_size=12, multi_probe_level=1)\n",
        "            search_params = dict(checks=50)\n",
        "            flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "            matches = flann.match(des1, des2)\n",
        "        else:\n",
        "            FLANN_INDEX_KDTREE = 1\n",
        "            index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
        "            search_params = dict(checks=50)\n",
        "            flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "            matches = flann.match(des1, des2)\n",
        "    matches = sorted(matches, key=lambda x: x.distance)\n",
        "    matched_img = cv2.drawMatches(img1, kp1, img2, kp2, matches[:20], None,\n",
        "                                  flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
        "    return matched_img\n",
        "\n",
        "# Template Matching\n",
        "def template_match(main_img: np.ndarray, templ: np.ndarray, threshold=0.8):\n",
        "    if len(main_img.shape) == 3:\n",
        "        main_gray = cv2.cvtColor(main_img, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        main_gray = main_img\n",
        "    if len(templ.shape) == 3:\n",
        "        templ_gray = cv2.cvtColor(templ, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        templ_gray = templ\n",
        "    result = cv2.matchTemplate(main_gray, templ_gray, cv2.TM_CCOEFF_NORMED)\n",
        "    loc = np.where(result >= threshold)\n",
        "    display = main_img.copy()\n",
        "    h, w = templ_gray.shape\n",
        "    for pt in zip(*loc[::-1]):\n",
        "        cv2.rectangle(display, pt, (pt[0] + w, pt[1] + h), (0, 0, 255), 2)\n",
        "    return display"
      ],
      "metadata": {
        "id": "pmYbOPvbrDSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GRADIO INTEGRATION**"
      ],
      "metadata": {
        "id": "hESSWrZrszpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tab: Basic Operations\n",
        "def tab_basic_ops(img1, img2, operation, r_factor, g_factor, b_factor, flip_dir,\n",
        "    trans_x, trans_y, scale_w, scale_h, scale_keep_aspect, rot_angle, rot_clockwise,\n",
        "    crop_x, crop_y, crop_w, crop_h, blend_alpha, bright_val, contrast_val, filter_lower_H,\n",
        "    filter_lower_S, filter_lower_V, filter_upper_H, filter_upper_S, filter_upper_V,\n",
        "    border_top, border_bottom, border_left, border_right, border_color_str, overlay_x,\n",
        "    overlay_y, overlay_alpha):\n",
        "    if img1 is None:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        color_tuple = tuple(map(int, border_color_str.split(',')))\n",
        "        if len(color_tuple) != 3:\n",
        "            color_tuple = (0, 0, 0)\n",
        "    except:\n",
        "        color_tuple = (0, 0, 0)\n",
        "\n",
        "    if operation == \"Greyscale\":\n",
        "        return to_greyscale(img1)\n",
        "    elif operation == \"Negative\":\n",
        "        return to_negative(img1)\n",
        "    elif operation == \"Adjust Color\":\n",
        "        return adjust_color(img1, r_factor, g_factor, b_factor)\n",
        "    elif operation == \"Flip\":\n",
        "        return flip_image(img1, flip_dir)\n",
        "    elif operation == \"Translate\":\n",
        "        return translate(img1, trans_x, trans_y)\n",
        "    elif operation == \"Scale\":\n",
        "        return scale_image(img1, width=scale_w, height=scale_h, keep_aspect_ratio=scale_keep_aspect)\n",
        "    elif operation == \"Rotate\":\n",
        "        return rotate(img1, rot_angle, clockwise=rot_clockwise)\n",
        "    elif operation == \"Crop\":\n",
        "        return crop(img1, crop_x, crop_y, crop_w, crop_h)\n",
        "    elif operation == \"Blend\":\n",
        "        return blend(img1, img2, alpha=blend_alpha)\n",
        "    elif operation == \"Brightness & Contrast\":\n",
        "        return adjust_brightness_contrast(img1, bright_val, contrast_val)\n",
        "    elif operation == \"Color Filter\":\n",
        "        lowerb = (filter_lower_H, filter_lower_S, filter_lower_V)\n",
        "        upperb = (filter_upper_H, filter_upper_S, filter_upper_V)\n",
        "\n",
        "        return color_filter(img1, lowerb, upperb)\n",
        "    elif operation == \"Sepia\":\n",
        "        return apply_sepia(img1)\n",
        "    elif operation == \"Cyanotype\":\n",
        "        return apply_cyanotype(img1)\n",
        "    elif operation == \"Add Border\":\n",
        "        return add_border(img1, border_top, border_bottom, border_left, border_right, color=color_tuple)\n",
        "    elif operation == \"Overlay\":\n",
        "        return overlay(img1, img2, overlay_x, overlay_y, alpha=overlay_alpha)\n",
        "    else:\n",
        "        return img1\n",
        "\n",
        "# Mathematical Operations\n",
        "def tab_pixelwise_op(image1, image2, operation):\n",
        "    if image1 is None:\n",
        "        return None\n",
        "    return pixelwise_operation(image1, image2, operation)\n",
        "\n",
        "# Transforms & Filtering\n",
        "def tab_transform_filter(image, operation, ksize=3, sigma=1.0, t1=50, t2=150):\n",
        "    if image is None:\n",
        "        return None\n",
        "    if operation == \"FFT\":\n",
        "        return fft_image(image)\n",
        "    elif operation == \"Mean Blur\":\n",
        "        return mean_blur(image, ksize)\n",
        "    elif operation == \"Gaussian Blur\":\n",
        "        return gaussian_blur(image, ksize, sigma)\n",
        "    elif operation == \"Median Blur\":\n",
        "        return median_blur(image, ksize)\n",
        "    elif operation == \"Sobel Edge\":\n",
        "        return sobel_edge(image, ksize)\n",
        "    elif operation == \"Canny Edge\":\n",
        "        return canny_edge(image, t1, t2)\n",
        "    elif operation == \"Laplacian Edge\":\n",
        "        return laplacian_edge(image, ksize)\n",
        "    else:\n",
        "        return image\n",
        "\n",
        "# Image Enhancement\n",
        "def tab_enhancement(image, operation, in_low=0, in_high=255, gamma_val=1.0):\n",
        "    if image is None:\n",
        "        return None\n",
        "    if operation == \"Histogram Equalization\":\n",
        "        return histogram_equalization(image)\n",
        "    elif operation == \"Contrast Stretching\":\n",
        "        return contrast_stretch(image, in_low, in_high)\n",
        "    elif operation == \"Gamma Correction\":\n",
        "        return gamma_correction(image, gamma_val)\n",
        "    else:\n",
        "        return image\n",
        "\n",
        "# Image Compression\n",
        "def tab_compression(image, operation, threshold_ratio=0.005):\n",
        "    if image is None:\n",
        "        return None\n",
        "    if operation == \"RLE\":\n",
        "        encoded = rle_encode(image)\n",
        "        decoded_image = rle_decode(encoded, image.shape[:2])\n",
        "        return decoded_image\n",
        "    elif operation == \"DCT\":\n",
        "        compressed_image = apply_dct(image, threshold_ratio=threshold_ratio)\n",
        "        return compressed_image\n",
        "    else:\n",
        "        return image\n",
        "\n",
        "# Image Segmentation\n",
        "def tab_segmentation(image, operation, threshold=128, block_size=11, C=2, k=3):\n",
        "    if image is None:\n",
        "        return None\n",
        "    if operation == \"Global Thresholding\":\n",
        "        return global_threshold(image, threshold)\n",
        "    elif operation == \"Adaptive Thresholding\":\n",
        "        return adaptive_threshold(image, block_size, C)\n",
        "    elif operation == \"K-Means\":\n",
        "        return kmeans_segmentation(image, k)\n",
        "    else:\n",
        "        return image\n",
        "\n",
        "# Binary Processing\n",
        "def tab_binary(image, operation, thresh=127, morph_op_='erosion', ksize=3, iterations=1):\n",
        "    if image is None:\n",
        "        return None\n",
        "    if operation == \"Binarize\":\n",
        "        return binarize_image(image, thresh)\n",
        "    elif operation == \"Morphological\":\n",
        "        bin_img = binarize_image(image, thresh=127) if len(image.shape) == 3 else image\n",
        "        return morphological_op(bin_img, morph_op_, ksize, iterations)\n",
        "    elif operation == \"Extract Boundary\":\n",
        "        bin_img = binarize_image(image, thresh=127) if len(image.shape) == 3 else image\n",
        "        return extract_boundary(bin_img, ksize=ksize)\n",
        "    elif operation == \"Skeletonize\":\n",
        "        bin_img = binarize_image(image, thresh=127) if len(image.shape) == 3 else image\n",
        "        return skeletonize_image(bin_img)\n",
        "    else:\n",
        "        return image\n",
        "\n",
        "# Image Restoration\n",
        "def tab_restoration(image, operation, ksize=5, sigma=1.0, noise_var=0.01, top_left_r=0, top_left_c=0, bot_right_r=10, bot_right_c=10, inpaint_radius=3):\n",
        "    if image is None:\n",
        "        return None\n",
        "    if operation == \"Add Noise + Wiener Filter\":\n",
        "        noisy = add_noise(image, 0, 25)\n",
        "        return wiener_filter(noisy, ksize, noise_var)\n",
        "    elif operation == \"Add Noise + Gaussian Filter\":\n",
        "        noisy = add_noise(image, 0, 25)\n",
        "        return gaussian_filter_restoration(noisy, ksize, sigma)\n",
        "    elif operation == \"Inpainting\":\n",
        "        return inpaint_image(image, (top_left_r, top_left_c), (bot_right_r, bot_right_c), inpaint_radius)\n",
        "    else:\n",
        "        return image\n",
        "\n",
        "# Image Matching\n",
        "def tab_matching(image1, image2, operation, feature_method='ORB', match_method='BF', templ_thresh=0.8):\n",
        "    if image1 is None or image2 is None:\n",
        "        return None\n",
        "    if operation == \"Feature Detection & Matching\":\n",
        "        return match_features(image1, image2, method=feature_method, match_method=match_method)\n",
        "    elif operation == \"Template Matching\":\n",
        "        return template_match(image1, image2, threshold=templ_thresh)\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "GDBTyBtarSpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GUI (Graphical User Interface)**"
      ],
      "metadata": {
        "id": "5K3CmZ1Vjurd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_demo():\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"## Image Processing And Recognition\")\n",
        "        with gr.Tabs():\n",
        "            # Basic Image Operations\n",
        "            with gr.TabItem(\"Basic Image Operations\"):\n",
        "                gr.Markdown(\"### Basic Image Operations\")\n",
        "\n",
        "                # Tab Greyscale\n",
        "                with gr.TabItem(\"Greyscale\"):\n",
        "                    with gr.Row():\n",
        "                        input_image_basic1 = gr.Image(label=\"Input Image 1\")\n",
        "                        output_image_basic = gr.Image(label=\"Output Image\")\n",
        "                    run_basic = gr.Button(\"Apply\")\n",
        "                    run_basic.click(\n",
        "                        fn=to_greyscale,\n",
        "                        inputs=[input_image_basic1],\n",
        "                        outputs=[output_image_basic]\n",
        "                    )\n",
        "\n",
        "                # Tab Negative\n",
        "                with gr.TabItem(\"Negative\"):\n",
        "                    with gr.Row():\n",
        "                        input_image_basic1 = gr.Image(label=\"Input Image 1\")\n",
        "                        output_image_basic = gr.Image(label=\"Output Image\")\n",
        "                    run_basic = gr.Button(\"Apply\")\n",
        "                    run_basic.click(\n",
        "                        fn=to_negative,\n",
        "                        inputs=[input_image_basic1],\n",
        "                        outputs=[output_image_basic]\n",
        "                    )\n",
        "\n",
        "                # Tab Adjust Color\n",
        "                with gr.TabItem(\"Adjust Color\"):\n",
        "                    with gr.Row():\n",
        "                        input_image_basic1 = gr.Image(label=\"Input Image 1\")\n",
        "                        output_image_basic = gr.Image(label=\"Output Image\")\n",
        "\n",
        "                    r_factor = gr.Slider(0.0, 2.0, value=1.0, step=0.1, label=\"Red Factor\")\n",
        "                    g_factor = gr.Slider(0.0, 2.0, value=1.0, step=0.1, label=\"Green Factor\")\n",
        "                    b_factor = gr.Slider(0.0, 2.0, value=1.0, step=0.1, label=\"Blue Factor\")\n",
        "\n",
        "                    run_basic = gr.Button(\"Apply\")\n",
        "                    run_basic.click(\n",
        "                        fn=adjust_color,\n",
        "                        inputs=[input_image_basic1, r_factor, g_factor, b_factor],\n",
        "                        outputs=[output_image_basic]\n",
        "                    )\n",
        "\n",
        "                # Tab Flip\n",
        "                with gr.TabItem(\"Flip\"):\n",
        "                    with gr.Row():\n",
        "                        input_image_basic1 = gr.Image(label=\"Input Image 1\")\n",
        "                        output_image_basic = gr.Image(label=\"Output Image\")\n",
        "\n",
        "                    flip_dir = gr.Dropdown([\"horizontal\", \"vertical\", \"diagonal\"], value=\"horizontal\", label=\"Flip Direction\")\n",
        "\n",
        "                    run_basic = gr.Button(\"Apply\")\n",
        "                    run_basic.click(\n",
        "                        fn=flip_image,\n",
        "                        inputs=[input_image_basic1, flip_dir],\n",
        "                        outputs=[output_image_basic]\n",
        "                    )\n",
        "\n",
        "                # Tab Translate\n",
        "                with gr.TabItem(\"Translate\"):\n",
        "                    with gr.Row():\n",
        "                        input_image_basic1 = gr.Image(label=\"Input Image 1\")\n",
        "                        output_image_basic = gr.Image(label=\"Output Image\")\n",
        "\n",
        "                    trans_x = gr.Slider(-200, 200, value=0, step=1, label=\"Translate X\")\n",
        "                    trans_y = gr.Slider(-200, 200, value=0, step=1, label=\"Translate Y\")\n",
        "\n",
        "                    run_basic = gr.Button(\"Apply\")\n",
        "                    run_basic.click(\n",
        "                        fn=translate,\n",
        "                        inputs=[input_image_basic1, trans_x, trans_y],\n",
        "                        outputs=[output_image_basic]\n",
        "                    )\n",
        "\n",
        "                # Tab Scale\n",
        "                with gr.TabItem(\"Scale\"):\n",
        "                    with gr.Row():\n",
        "                        input_image_basic1 = gr.Image(label=\"Input Image 1\")\n",
        "                        output_image_basic = gr.Image(label=\"Output Image\")\n",
        "\n",
        "                    scale_w = gr.Number(value=None, label=\"Scale Width (None=auto)\")\n",
        "                    scale_h = gr.Number(value=None, label=\"Scale Height (None=auto)\")\n",
        "                    scale_keep_aspect = gr.Checkbox(value=True, label=\"Keep Aspect Ratio\")\n",
        "\n",
        "                    run_basic = gr.Button(\"Apply\")\n",
        "                    run_basic.click(\n",
        "                        fn=scale_image,\n",
        "                        inputs=[input_image_basic1, scale_w, scale_h, scale_keep_aspect],\n",
        "                        outputs=[output_image_basic]\n",
        "                    )\n",
        "\n",
        "                # Tab Rotate\n",
        "                with gr.TabItem(\"Rotate\"):\n",
        "                    with gr.Row():\n",
        "                        input_image_basic1 = gr.Image(label=\"Input Image 1\")\n",
        "                        output_image_basic = gr.Image(label=\"Output Image\")\n",
        "\n",
        "                    rot_angle = gr.Slider(-180, 180, value=0, step=1, label=\"Rotate Angle\")\n",
        "                    rot_clockwise = gr.Checkbox(value=True, label=\"Rotate Clockwise\")\n",
        "\n",
        "                    run_basic = gr.Button(\"Apply\")\n",
        "                    run_basic.click(\n",
        "                        fn=rotate,\n",
        "                        inputs=[input_image_basic1, rot_angle, rot_clockwise],\n",
        "                        outputs=[output_image_basic]\n",
        "                    )\n",
        "\n",
        "                # Tab Crop\n",
        "                with gr.TabItem(\"Crop\"):\n",
        "                    with gr.Row():\n",
        "                        input_image_basic1 = gr.Image(label=\"Input Image 1\")\n",
        "                        output_image_basic = gr.Image(label=\"Output Image\")\n",
        "\n",
        "                    crop_x = gr.Slider(0, 300, value=0, step=1, label=\"Crop X\")\n",
        "                    crop_y = gr.Slider(0, 300, value=0, step=1, label=\"Crop Y\")\n",
        "                    crop_w = gr.Slider(0, 300, value=100, step=1, label=\"Crop Width\")\n",
        "                    crop_h = gr.Slider(0, 300, value=100, step=1, label=\"Crop Height\")\n",
        "\n",
        "                    run_basic = gr.Button(\"Apply\")\n",
        "                    run_basic.click(\n",
        "                        fn=crop,\n",
        "                        inputs=[input_image_basic1, crop_x, crop_y, crop_w, crop_h],\n",
        "                        outputs=[output_image_basic]\n",
        "                    )\n",
        "\n",
        "                # Tab Blend\n",
        "                with gr.TabItem(\"Blend\"):\n",
        "                    with gr.Row():\n",
        "                        input_image_basic1 = gr.Image(label=\"Input Image 1\")\n",
        "                        input_image_basic2 = gr.Image(label=\"Input Image 2 (for blend)\")\n",
        "                        output_image_basic = gr.Image(label=\"Output Image\")\n",
        "\n",
        "                    blend_alpha = gr.Slider(0.0, 1.0, value=0.5, step=0.05, label=\"Blend Alpha\")\n",
        "\n",
        "                    run_basic = gr.Button(\"Apply\")\n",
        "                    run_basic.click(\n",
        "                        fn=blend,\n",
        "                        inputs=[input_image_basic1, input_image_basic2, blend_alpha],\n",
        "                        outputs=[output_image_basic]\n",
        "                    )\n",
        "\n",
        "                # Tab Brightness & Contrast\n",
        "                with gr.TabItem(\"Brightness & Contrast\"):\n",
        "                    with gr.Row():\n",
        "                        input_image_basic1 = gr.Image(label=\"Input Image 1\")\n",
        "                        output_image_basic = gr.Image(label=\"Output Image\")\n",
        "\n",
        "                    bright_val = gr.Slider(-100, 100, value=50, step=1, label=\"Brightness\")\n",
        "                    contrast_val = gr.Slider(0.1, 3.0, value=1.2, step=0.1, label=\"Contrast\")\n",
        "\n",
        "                    run_basic = gr.Button(\"Apply\")\n",
        "                    run_basic.click(\n",
        "                        fn=adjust_brightness_contrast,\n",
        "                        inputs=[input_image_basic1, bright_val, contrast_val],\n",
        "                        outputs=[output_image_basic]\n",
        "                    )\n",
        "\n",
        "                # Tab Color Filter\n",
        "                with gr.TabItem(\"Color Filter\"):\n",
        "                    with gr.Row():\n",
        "                        input_image_basic1 = gr.Image(label=\"Input Image 1\")\n",
        "                        output_image_basic = gr.Image(label=\"Output Image\")\n",
        "\n",
        "                    filter_type = gr.Radio(\n",
        "                        [\"Custom\", \"Sepia\", \"Cyanotype\"],\n",
        "                        label=\"Select Filter Type\",\n",
        "                        value=\"Custom\",\n",
        "                    )\n",
        "\n",
        "                    filter_lower_H = gr.Slider(0, 179, value=0, step=1, label=\"Filter Lower H\")\n",
        "                    filter_lower_S = gr.Slider(0, 255, value=0, step=1, label=\"Filter Lower S\")\n",
        "                    filter_lower_V = gr.Slider(0, 255, value=0, step=1, label=\"Filter Lower V\")\n",
        "\n",
        "                    filter_upper_H = gr.Slider(0, 179, value=179, step=1, label=\"Filter Upper H\")\n",
        "                    filter_upper_S = gr.Slider(0, 255, value=255, step=1, label=\"Filter Upper S\")\n",
        "                    filter_upper_V = gr.Slider(0, 255, value=255, step=1, label=\"Filter Upper V\")\n",
        "\n",
        "                    run_basic = gr.Button(\"Apply\")\n",
        "\n",
        "                    def apply_selected_filter(image, filter_type, lower_H, lower_S, lower_V, upper_H, upper_S, upper_V):\n",
        "                        if filter_type == \"Custom\":\n",
        "                            lowerb = (lower_H, lower_S, lower_V)\n",
        "                            upperb = (upper_H, upper_S, upper_V)\n",
        "                            return color_filter(image, lowerb, upperb)\n",
        "                        elif filter_type == \"Sepia\":\n",
        "                            return apply_sepia(image)\n",
        "                        elif filter_type == \"Cyanotype\":\n",
        "                            return apply_cyanotype(image)\n",
        "\n",
        "                    run_basic.click(\n",
        "                        fn=apply_selected_filter,\n",
        "                        inputs=[input_image_basic1, filter_type, filter_lower_H, filter_lower_S, filter_lower_V, filter_upper_H, filter_upper_S, filter_upper_V],\n",
        "                        outputs=[output_image_basic]\n",
        "                    )\n",
        "\n",
        "                # Tab Add Border\n",
        "                with gr.TabItem(\"Add Border\"):\n",
        "                    with gr.Row():\n",
        "                        input_image_basic1 = gr.Image(label=\"Input Image 1\")\n",
        "                        output_image_basic = gr.Image(label=\"Output Image\")\n",
        "\n",
        "                    border_top = gr.Slider(0, 100, value=0, step=1, label=\"Border Top\")\n",
        "                    border_bottom = gr.Slider(0, 100, value=0, step=1, label=\"Border Bottom\")\n",
        "                    border_left = gr.Slider(0, 100, value=0, step=1, label=\"Border Left\")\n",
        "                    border_right = gr.Slider(0, 100, value=0, step=1, label=\"Border Right\")\n",
        "                    border_color_str = gr.Textbox(value=\"0,0,0\", label=\"Border Color (R,G,B)\")\n",
        "\n",
        "                    run_basic = gr.Button(\"Apply\")\n",
        "                    run_basic.click(\n",
        "                        fn=add_border,\n",
        "                        inputs=[input_image_basic1, border_top, border_bottom, border_left, border_right, border_color_str],\n",
        "                        outputs=[output_image_basic]\n",
        "                    )\n",
        "\n",
        "                # Tab Overlay\n",
        "                with gr.TabItem(\"Overlay\"):\n",
        "                    with gr.Row():\n",
        "                        input_image_basic1 = gr.Image(label=\"Input Image 1\")\n",
        "                        input_image_basic2 = gr.Image(label=\"Input Image 2 (for overlay)\")\n",
        "                        output_image_basic = gr.Image(label=\"Output Image\")\n",
        "\n",
        "                    overlay_x = gr.Slider(0, 300, value=0, step=1, label=\"Overlay X\")\n",
        "                    overlay_y = gr.Slider(0, 300, value=0, step=1, label=\"Overlay Y\")\n",
        "                    overlay_alpha = gr.Slider(0.0, 1.0, value=0.5, step=0.05, label=\"Overlay Alpha\")\n",
        "\n",
        "                    run_basic = gr.Button(\"Apply\")\n",
        "                    run_basic.click(\n",
        "                        fn=overlay,\n",
        "                        inputs=[input_image_basic1, input_image_basic2, overlay_x, overlay_y, overlay_alpha],\n",
        "                        outputs=[output_image_basic]\n",
        "                    )\n",
        "\n",
        "            # Mathematical Operations\n",
        "            with gr.TabItem(\"Mathematical Operations\"):\n",
        "                gr.Markdown(\"### Mathematical Operations on Images\")\n",
        "                with gr.Row():\n",
        "                    input_image_math1 = gr.Image(label=\"Input Image 1\")\n",
        "                    input_image_math2 = gr.Image(label=\"Input Image 2 (ignored if NOT)\")\n",
        "                    output_image_math = gr.Image(label=\"Output Image\")\n",
        "\n",
        "                operation_math = gr.Radio(\n",
        "                    choices=[\"Add\", \"Subtract\", \"Multiply\", \"Divide\",\n",
        "                             \"Bitwise (AND)\", \"Bitwise (OR)\", \"Bitwise (XOR)\", \"Bitwise (NOT)\"],\n",
        "                    value=\"add\",\n",
        "                    label=\"Pixelwise Operation\"\n",
        "                )\n",
        "                run_math = gr.Button(\"Apply Operation\")\n",
        "                run_math.click(\n",
        "                    tab_pixelwise_op,\n",
        "                    inputs=[input_image_math1, input_image_math2, operation_math],\n",
        "                    outputs=[output_image_math]\n",
        "                )\n",
        "\n",
        "            # Transforms & Filtering\n",
        "            with gr.TabItem(\"Transforms & Filtering\"):\n",
        "                gr.Markdown(\"### Transforms & Filtering\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    input_image_tf = gr.Image(type=\"numpy\", label=\"Input Image\")  # Ensure 'numpy' type for the input image\n",
        "                    output_image_tf = gr.Image(type=\"numpy\", label=\"Output Image\")  # Ensure 'numpy' type for the output image\n",
        "\n",
        "                # Dropdown to choose operation\n",
        "                operation_tf = gr.Radio(\n",
        "                    choices=[\"FFT\", \"Mean Blur\", \"Gaussian Blur\", \"Median Blur\",\n",
        "                            \"Sobel Edge\", \"Canny Edge\", \"Laplacian Edge\"],\n",
        "                    value=\"FFT\",\n",
        "                    label=\"Select Operation\"\n",
        "                )\n",
        "\n",
        "                # Sliders for kernel size, sigma, and Canny thresholds\n",
        "                ksize_tf = gr.Slider(1, 15, step=1, value=3, label=\"Kernel Size (blur/edge)\")\n",
        "                sigma_tf = gr.Slider(0.1, 5.0, step=0.1, value=1.0, label=\"Sigma (Gaussian)\")\n",
        "                t1_tf = gr.Slider(0, 255, value=50, step=1, label=\"Canny Threshold1\")\n",
        "                t2_tf = gr.Slider(0, 255, value=150, step=1, label=\"Canny Threshold2\")\n",
        "\n",
        "                run_tf = gr.Button(\"Process\")\n",
        "                def _process_tf(img, op, k, s, c1, c2):\n",
        "                    return tab_transform_filter(img, op, k, s, c1, c2)\n",
        "\n",
        "                # Set up the button click interaction\n",
        "                run_tf.click(_process_tf,\n",
        "                            inputs=[input_image_tf, operation_tf, ksize_tf, sigma_tf, t1_tf, t2_tf],\n",
        "                            outputs=[output_image_tf])\n",
        "\n",
        "            # Enhancement\n",
        "            with gr.TabItem(\"Enhancement\"):\n",
        "                gr.Markdown(\"### Image Enhancement\")\n",
        "                with gr.Row():\n",
        "                    input_image_en = gr.Image(label=\"Input Image\")\n",
        "                    output_image_en = gr.Image(label=\"Output Image\")\n",
        "\n",
        "                operation_en = gr.Radio(\n",
        "                    choices=[\"Histogram Equalization\", \"Contrast Stretching\", \"Gamma Correction\"],\n",
        "                    value=\"Histogram Equalization\",\n",
        "                    label=\"Select Enhancement\"\n",
        "                )\n",
        "                in_low_en = gr.Slider(0, 255, value=0, step=1, label=\"In Low (Contrast Stretch)\")\n",
        "                in_high_en = gr.Slider(0, 255, value=255, step=1, label=\"In High (Contrast Stretch)\")\n",
        "                gamma_en = gr.Slider(0.1, 5.0, value=1.0, step=0.1, label=\"Gamma\")\n",
        "\n",
        "                run_en = gr.Button(\"Enhance\")\n",
        "                def _process_en(img, op, low, high, gm):\n",
        "                    return tab_enhancement(img, op, low, high, gm)\n",
        "                run_en.click(_process_en,\n",
        "                             inputs=[input_image_en, operation_en, in_low_en, in_high_en, gamma_en],\n",
        "                             outputs=[output_image_en])\n",
        "\n",
        "            # Compression\n",
        "            with gr.TabItem(\"Compression\"):\n",
        "                gr.Markdown(\"### Image Compression\")\n",
        "                with gr.Row():\n",
        "                    input_image_comp = gr.Image(label=\"Input Image\")\n",
        "                    output_comp_image = gr.Image(label=\"Output Image\", interactive=False)\n",
        "\n",
        "                operation_comp = gr.Radio(\n",
        "                    choices=[\"RLE\", \"DCT\"],\n",
        "                    value=\"RLE\",\n",
        "                    label=\"Select Compression\"\n",
        "                )\n",
        "\n",
        "                run_comp = gr.Button(\"Compress\")\n",
        "\n",
        "                def _process_comp(img, op):\n",
        "                    result = tab_compression(img, op)\n",
        "                    return result\n",
        "\n",
        "                run_comp.click(\n",
        "                    _process_comp,\n",
        "                    inputs=[input_image_comp, operation_comp],\n",
        "                    outputs=[output_comp_image]\n",
        "                )\n",
        "\n",
        "            # Tab: Segmentation\n",
        "            with gr.TabItem(\"Segmentation\"):\n",
        "                gr.Markdown(\"### Image Segmentation\")\n",
        "                with gr.Row():\n",
        "                    input_image_seg = gr.Image(label=\"Input Image\")\n",
        "                    output_image_seg = gr.Image(label=\"Output Image\")\n",
        "\n",
        "                operation_seg = gr.Radio(\n",
        "                    choices=[\"Global Thresholding\", \"Adaptive Thresholding\", \"K-Means\"],\n",
        "                    value=\"Global Thresholding\",\n",
        "                    label=\"Select Segmentation\"\n",
        "                )\n",
        "                thresh_seg = gr.Slider(0, 255, value=128, step=1, label=\"Threshold (Global)\")\n",
        "                block_seg = gr.Slider(3, 31, step=2, value=11, label=\"Block Size (Adaptive)\")\n",
        "                c_seg = gr.Slider(0, 10, value=2, step=1, label=\"C (Adaptive)\")\n",
        "                k_seg = gr.Slider(2, 10, value=3, step=1, label=\"K (K-Means)\")\n",
        "\n",
        "                run_seg = gr.Button(\"Segment\")\n",
        "                def _process_seg(img, op, th, bs, c_, k_):\n",
        "                    return tab_segmentation(img, op, th, bs, c_, k_)\n",
        "                run_seg.click(_process_seg,\n",
        "                              inputs=[input_image_seg, operation_seg, thresh_seg, block_seg, c_seg, k_seg],\n",
        "                              outputs=[output_image_seg])\n",
        "\n",
        "            # Tab: Binary Processing\n",
        "            with gr.TabItem(\"Binary Processing\"):\n",
        "                gr.Markdown(\"### Binary Image Processing\")\n",
        "                with gr.Row():\n",
        "                    input_image_bin = gr.Image(label=\"Input Image\")\n",
        "                    output_image_bin = gr.Image(label=\"Output Image\")\n",
        "\n",
        "                operation_bin = gr.Radio(\n",
        "                    choices=[\"Binarize\", \"Morphological\", \"Extract Boundary\", \"Skeletonize\"],\n",
        "                    value=\"Binarize\",\n",
        "                    label=\"Select Operation\"\n",
        "                )\n",
        "                thresh_bin = gr.Slider(0, 255, value=127, step=1, label=\"Threshold\")\n",
        "                morph_op_bin = gr.Dropdown(\n",
        "                    choices=[\"erosion\", \"dilation\", \"opening\", \"closing\"],\n",
        "                    value=\"erosion\",\n",
        "                    label=\"Morphological Operation\"\n",
        "                )\n",
        "                ksize_bin = gr.Slider(1, 15, value=3, step=1, label=\"Kernel Size\")\n",
        "                iter_bin = gr.Slider(1, 10, value=1, step=1, label=\"Iterations\")\n",
        "\n",
        "                run_bin = gr.Button(\"Process Binary\")\n",
        "                def _process_bin(img, op, th, mop, ks, iters):\n",
        "                    return tab_binary(img, op, th, mop, ks, iters)\n",
        "                run_bin.click(_process_bin,\n",
        "                              inputs=[input_image_bin, operation_bin, thresh_bin, morph_op_bin, ksize_bin, iter_bin],\n",
        "                              outputs=[output_image_bin])\n",
        "\n",
        "            # Tab: Restoration\n",
        "            with gr.TabItem(\"Restoration\"):\n",
        "                gr.Markdown(\"### Image Restoration\")\n",
        "                with gr.Row():\n",
        "                    input_image_rest = gr.Image(label=\"Input Image\")\n",
        "                    output_image_rest = gr.Image(label=\"Output Image\")\n",
        "\n",
        "                operation_rest = gr.Radio(\n",
        "                    choices=[\"Add Noise + Wiener Filter\", \"Add Noise + Gaussian Filter\", \"Inpainting\"],\n",
        "                    value=\"Add Noise + Wiener Filter\",\n",
        "                    label=\"Select Restoration\"\n",
        "                )\n",
        "                ksize_rest = gr.Slider(1, 15, value=5, step=1, label=\"Kernel Size (Wiener/Gaussian)\")\n",
        "                sigma_rest = gr.Slider(0.1, 5.0, value=1.0, step=0.1, label=\"Sigma (Gaussian)\")\n",
        "                noise_var_rest = gr.Slider(0.001, 1.0, value=0.01, step=0.01, label=\"Noise Var (Wiener)\")\n",
        "                top_left_r = gr.Number(value=0, label=\"Inpaint Top Row\")\n",
        "                top_left_c = gr.Number(value=0, label=\"Inpaint Left Col\")\n",
        "                bot_right_r = gr.Number(value=50, label=\"Inpaint Bottom Row\")\n",
        "                bot_right_c = gr.Number(value=50, label=\"Inpaint Right Col\")\n",
        "                inpaint_rad = gr.Slider(1, 10, value=3, step=1, label=\"Inpaint Radius\")\n",
        "\n",
        "                run_rest = gr.Button(\"Restore\")\n",
        "                def _process_rest(img, op, ks, sg, nv, r1, c1, r2, c2, ipr):\n",
        "                    return tab_restoration(img, op, ks, sg, nv, int(r1), int(c1), int(r2), int(c2), ipr)\n",
        "                run_rest.click(_process_rest,\n",
        "                               inputs=[input_image_rest, operation_rest, ksize_rest, sigma_rest, noise_var_rest,\n",
        "                                       top_left_r, top_left_c, bot_right_r, bot_right_c, inpaint_rad],\n",
        "                               outputs=[output_image_rest])\n",
        "\n",
        "            # Tab: Matching\n",
        "            with gr.TabItem(\"Matching\"):\n",
        "                gr.Markdown(\"### Image Matching\")\n",
        "                with gr.Row():\n",
        "                    input_image_match1 = gr.Image(label=\"Main Image / Image1\")\n",
        "                    input_image_match2 = gr.Image(label=\"Template / Image2\")\n",
        "                output_image_match = gr.Image(label=\"Output Image\")\n",
        "\n",
        "                operation_match = gr.Radio(\n",
        "                    choices=[\"Feature Detection & Matching\", \"Template Matching\"],\n",
        "                    value=\"Feature Detection & Matching\",\n",
        "                    label=\"Select Matching Operation\"\n",
        "                )\n",
        "                feature_method = gr.Dropdown(choices=[\"ORB\", \"SIFT\"], value=\"ORB\", label=\"Feature Method\")\n",
        "                match_method = gr.Dropdown(choices=[\"BF\", \"FLANN\"], value=\"BF\", label=\"Match Method\")\n",
        "                templ_thresh = gr.Slider(0.0, 1.0, value=0.8, step=0.01, label=\"Template Threshold\")\n",
        "\n",
        "                run_match = gr.Button(\"Match\")\n",
        "                def _process_match(img1, img2, op, fm, mm, thr):\n",
        "                    return tab_matching(img1, img2, op, fm, mm, thr)\n",
        "                run_match.click(_process_match,\n",
        "                                inputs=[input_image_match1, input_image_match2, operation_match,\n",
        "                                        feature_method, match_method, templ_thresh],\n",
        "                                outputs=[output_image_match])\n",
        "    return demo\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo = build_demo()\n",
        "    demo.launch()"
      ],
      "metadata": {
        "id": "0vMqy0CFjg69"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}